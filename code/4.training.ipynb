{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.modeling import VisionTransformer, CONFIGS\n",
    "from data_utils.cifarn_dataset import CIFAR10\n",
    "from models_vgg import vgg11_bn\n",
    "from models_dense import densenet121\n",
    "from models_resnet import resnet50\n",
    "import numpy as np\n",
    "import torch\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchsummary import summary\n",
    "import torchmetrics.functional.classification as M\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2 # set K\n",
    "\n",
    "# set below according to the number of times the noisy labels were augmented.\n",
    "# when K=2, there are 2 clusters. \n",
    "\n",
    "augs = ['a1', 'a2', 'a3'] # When training m_theta for cluster 1 uncomment this and comment below\n",
    "augs = ['a4', 'a5', 'a6'] # When training m_theta for cluster 2 uncomment this and comment above\n",
    "\n",
    "# this is to follow how training sets were created in identifying_annot_profiles.ipynb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def evaluate(model, dataloader, device, show=True, criterion=None): # to test the model\n",
    "    # model results\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = torch.tensor([]).to(device)\n",
    "        groundTruth = torch.tensor([]).to(device)\n",
    "        for i, (imgs, labels, n_labels) in enumerate(dataloader):\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            n_labels = n_labels.to(device)\n",
    "            n_labels = F.one_hot(n_labels, num_classes=10).to(device, dtype=torch.float32)\n",
    "\n",
    "            base, user, outputs = model(imgs, n_labels)\n",
    "            if criterion:\n",
    "                loss = criterion(outputs, torch.argmax(n_labels, dim=1), labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            predictions = torch.cat((predictions, preds))\n",
    "            groundTruth = torch.cat((groundTruth, labels))\n",
    "\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    groundTruth = groundTruth.detach().cpu().numpy()\n",
    "\n",
    "    if show:\n",
    "        print(classification_report(y_true=groundTruth, y_pred=predictions))\n",
    "        ConfusionMatrixDisplay(confusion_matrix(groundTruth, predictions)).plot()\n",
    "        return groundTruth, predictions\n",
    "    else:\n",
    "        return classification_report(y_true=groundTruth, y_pred=predictions, output_dict=True)['accuracy'], loss.item() if criterion else None\n",
    "    \n",
    "def getClusterNoiseMatrix(trainloader):\n",
    "    predictions = torch.tensor([]).to(device)\n",
    "    groundTruth = torch.tensor([]).to(device)\n",
    "\n",
    "    for i, (imgs, labels, n_labels) in enumerate(trainloader):\n",
    "        labels = labels.to(device)\n",
    "        n_labels = n_labels.to(device)\n",
    "\n",
    "        predictions = torch.cat((predictions, n_labels))\n",
    "        groundTruth = torch.cat((groundTruth, labels))\n",
    "\n",
    "    predictions = predictions.detach().cpu().numpy()\n",
    "    groundTruth = groundTruth.detach().cpu().numpy()\n",
    "\n",
    "    # to get the cluster noise\n",
    "    noise_matrix = confusion_matrix(groundTruth, predictions, normalize='true')\n",
    "    return noise_matrix\n",
    "\n",
    "class CorrectionLoss(nn.Module):\n",
    "    def __init__(self, loss1, C=0, N_human=None, N_base=None):\n",
    "        super().__init__()\n",
    "        self.loss1 = loss1\n",
    "        self.C = C\n",
    "        self.N_h = N_human\n",
    "        self.N_b = N_base\n",
    "    \n",
    "    def noiseCorrection(self, prediction, n_input):\n",
    "        softmax_pred = F.softmax(prediction, dim=1)\n",
    "        correction = torch.tensor([]).to(device=device)\n",
    "\n",
    "        if self.N_h is not None:\n",
    "            loss_h = F.nll_loss(torch.log(torch.matmul(softmax_pred, self.N_h)), n_input, reduction='mean')\n",
    "            correction = torch.cat((correction, torch.tensor([loss_h]).to(device)))\n",
    "\n",
    "        if self.N_b is not None:\n",
    "            loss_b = F.nll_loss(torch.log(torch.matmul(softmax_pred, self.N_b)), n_input, reduction='mean')\n",
    "            correction = torch.cat((correction, torch.tensor([loss_b]).to(device)))\n",
    "\n",
    "        return self.C * torch.mean(correction)\n",
    "             \n",
    "    def forward(self, prediction, n_input, target):\n",
    "            l = self.loss1(prediction, target) \n",
    "            correction = self.noiseCorrection(prediction, n_input)\n",
    "            return l+correction\n",
    "    \n",
    "def saveModel(model, modelName):\n",
    "    model_path = 'adapt_models/' + modelName + '_{}'.format(datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
    "    torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "torch.random.manual_seed(0)\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.05, 1.0)),\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.CIFAR10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "trainset = CIFAR10(root=\"./data/\", k=k, augs=augs, train=True, download=False, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=512, shuffle=True, num_workers=1)\n",
    "\n",
    "testset = CIFAR10(root=\"./data/\", k=k, augs=augs, train=False, download=False, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=512, shuffle=False, num_workers=1)\n",
    "\n",
    "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Any model architecture of your choice can be used for base model and assign it as self.base_model below.\n",
    "Vit is used in this sample.\n",
    "\n",
    "Output of the base model should be the a logit having the size of no. of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptedAI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdaptedAI, self).__init__()\n",
    "        self.base_model = VisionTransformer(CONFIGS['ViT-B_16'], 224, zero_head=True, num_classes=10)\n",
    "        # loading the trained base model with consensus labels (at the end of the crowdlab process)\n",
    "        # self.base_model.load_state_dict(torch.load(\"path/to/base_model.bin\", map_location=torch.device(device)))\n",
    "\n",
    "        self.base_model.to(device)\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # to encode the noisy lable\n",
    "        self.n_l_encoder = nn.Sequential(\n",
    "            nn.Linear(10, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "\n",
    "        # input -> img + noisy lable\n",
    "        self.decision_ai = nn.Sequential(\n",
    "            nn.Linear(20, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs, n_l):\n",
    "        img_features = self.base_model(imgs)[0] # [0] is because of how vit is designed\n",
    "        n_l_features = self.n_l_encoder(n_l)\n",
    "\n",
    "        out = torch.cat((img_features, n_l_features), dim=1)\n",
    "        out = self.decision_ai(out)\n",
    "        return img_features, n_l, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=10, bias=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adapt_model = AdaptedAI().to(device)\n",
    "for param in adapt_model.base_model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# make trainable base model layers as needed\n",
    "adapt_model.base_model.head.requires_grad_(True)\n",
    "\n",
    "# loading the trained m_theta if needed\n",
    "# adapt_model.load_state_dict(torch.load('./adapt_models/k1_vitb16_l.1_20230817_181808', map_location=torch.device(device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the cluster noise matrix\n",
    "noise_matrix = getClusterNoiseMatrix(trainloader)\n",
    "noise_H = torch.tensor(noise_matrix).to(dtype=torch.float32, device=device)\n",
    "\n",
    "# additionally, can use the base model's noise matrix as well, if needed.\n",
    "# check CorrectionLoss implementation\n",
    "noise_B = np.array([\n",
    "])\n",
    "noise_B = torch.tensor(noise_B).to(dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CorrectionLoss(nn.CrossEntropyLoss(), 0.1, noise_H)\n",
    "optimizer = optim.Adam(adapt_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.90\n",
    "global_step = 0.0\n",
    "writer = SummaryWriter('./adapt_logs/training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "EPOCHS = 1\n",
    "for e in range(EPOCHS):\n",
    "    for i, (imgs, labels, n_labels) in enumerate(trainloader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        n_labels = n_labels.to(device)\n",
    "        n_labels = F.one_hot(n_labels, num_classes=10).to(device, dtype=torch.float32)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        _, _, outputs = adapt_model(imgs, n_labels)\n",
    "\n",
    "        loss = criterion(outputs, torch.argmax(n_labels, dim=1), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss = loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_acc = torch.sum(preds == labels.data).item() / len(labels)\n",
    "\n",
    "        print(\"epoch:{}, batch:{}, loss:{}, acc:{}\".format(e+1, i+1, running_loss, running_acc))\n",
    "        global_step += 1\n",
    "        writer.add_scalar(\"Train/Loss\", running_loss, global_step)\n",
    "        writer.add_scalar(\"Train/Acc\", running_acc, global_step)\n",
    "    \n",
    "    test_acc, test_loss = evaluate(adapt_model, testloader, device, False, criterion)\n",
    "    writer.add_scalar(\"Test/Loss\", test_loss, global_step)\n",
    "    writer.add_scalar(\"Test/Acc\", test_acc, global_step)\n",
    "    if test_acc > best_acc:\n",
    "        print(\"Accuracy\", test_acc)\n",
    "        best_acc = test_acc\n",
    "        saveModel(adapt_model, \"model\")\n",
    "\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(adapt_model, testloader, device, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
