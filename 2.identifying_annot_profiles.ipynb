{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dileepa/miniconda3/envs/noisy_env/lib/python3.9/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 803: system has unsupported display driver / cuda driver combination (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import cleanlab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pylab as plt\n",
    "import sklearn_extensions.fuzzy_kmeans as Fuzz\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump, load\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import CategoricalNB, GaussianNB\n",
    "\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Training and Testing Users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aim is to make $L.C$ vectors for users so that they can be clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image-batch</th>\n",
       "      <th>Worker1-id</th>\n",
       "      <th>Worker2-id</th>\n",
       "      <th>Worker3-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0--9</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10--19</td>\n",
       "      <td>430</td>\n",
       "      <td>140</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20--29</td>\n",
       "      <td>601</td>\n",
       "      <td>430</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30--39</td>\n",
       "      <td>545</td>\n",
       "      <td>79</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40--49</td>\n",
       "      <td>631</td>\n",
       "      <td>373</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image-batch  Worker1-id  Worker2-id  Worker3-id\n",
       "0        0--9         198         385         197\n",
       "1      10--19         430         140         584\n",
       "2      20--29         601         430         631\n",
       "3      30--39         545          79         385\n",
       "4      40--49         631         373         177"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ori = pd.read_csv('../cifar10n_no_gt_modified/data/side_info_cifar10N.csv')\n",
    "data_ori = data_ori.loc[:, ['Image-batch', 'Worker1-id', 'Worker2-id', 'Worker3-id']]\n",
    "data_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image-batch</th>\n",
       "      <th>Worker1-id</th>\n",
       "      <th>Worker2-id</th>\n",
       "      <th>Worker3-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>198</td>\n",
       "      <td>385</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Image-batch  Worker1-id  Worker2-id  Worker3-id\n",
       "0           0         198         385         197\n",
       "0           1         198         385         197\n",
       "0           2         198         385         197\n",
       "0           3         198         385         197\n",
       "0           4         198         385         197"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (0--4) to [0, 4]\n",
    "data_ori['Image-batch'] = data_ori['Image-batch'].map(lambda x: [i for i in x.split('-') if len(i.strip()) > 0])\n",
    "# [0, 4] to [0, 1, 2, 3, 4]\n",
    "data_ori['Image-batch'] = data_ori['Image-batch'].map(lambda x: list(range(int(x[0]), int(x[1])+1)))\n",
    "# get [0, 1, 2, 3, 4] to rows while duplicating other info\n",
    "data_ori = data_ori.explode('Image-batch')\n",
    "data_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 2) (50000, 2) (50000, 2)\n"
     ]
    }
   ],
   "source": [
    "w1 = data_ori.loc[:, ['Image-batch', 'Worker1-id']].reset_index(drop=True)\n",
    "w2 = data_ori.loc[:, ['Image-batch', 'Worker2-id']].reset_index(drop=True)\n",
    "w3 = data_ori.loc[:, ['Image-batch', 'Worker3-id']].reset_index(drop=True)\n",
    "print(w1.shape, w2.shape, w3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4) (50000, 4) (50000, 4)\n"
     ]
    }
   ],
   "source": [
    "c10n = torch.load('../cifar10n_no_gt_modified/data/CIFAR-10_human.pt')\n",
    "step2_labels = torch.load('../cifar10n_no_gt_modified/c_10n_noise.pt')['c_10n_step2']\n",
    "\n",
    "w1['chosen_label'] = c10n['random_label1']\n",
    "w1['true_label'] = step2_labels\n",
    "\n",
    "w2['chosen_label'] = c10n['random_label2']\n",
    "w2['true_label'] = step2_labels\n",
    "\n",
    "w3['chosen_label'] = c10n['random_label3']\n",
    "w3['true_label'] = step2_labels\n",
    "\n",
    "print(w1.shape, w2.shape, w3.shape)\n",
    "\n",
    "w1.rename(columns={'Worker1-id': 'annotator_id', 'Image-batch': 'c10_train_index'}, inplace=True)\n",
    "w2.rename(columns={'Worker2-id': 'annotator_id', 'Image-batch': 'c10_train_index'}, inplace=True)\n",
    "w3.rename(columns={'Worker3-id': 'annotator_id', 'Image-batch': 'c10_train_index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c10_train_index</th>\n",
       "      <th>annotator_id</th>\n",
       "      <th>chosen_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>198</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>49995</td>\n",
       "      <td>169</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>49996</td>\n",
       "      <td>169</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>49997</td>\n",
       "      <td>169</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>49998</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>49999</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       c10_train_index  annotator_id  chosen_label  true_label\n",
       "0                    0           198             6           6\n",
       "1                    1           198             9           9\n",
       "2                    2           198             9           9\n",
       "3                    3           198             4           4\n",
       "4                    4           198             1           1\n",
       "...                ...           ...           ...         ...\n",
       "149995           49995           169             2           2\n",
       "149996           49996           169             6           6\n",
       "149997           49997           169             9           9\n",
       "149998           49998           169             1           1\n",
       "149999           49999           169             1           1\n",
       "\n",
       "[150000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.concat([w1, w2, w3], ignore_index=True)\n",
    "print(raw.shape)\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_annotators: 747\n",
      "max annotations by one person: 3070\n",
      "min annotations by one person: 10\n",
      "mean annotations by one person: 200.80321285140562 \n",
      "\n",
      "n_unique images annotated: 50000\n",
      "max annotations per image: 3\n",
      "min annotations per image: 3\n",
      "mean annotations per image: 3.0\n"
     ]
    }
   ],
   "source": [
    "n_unique_annotators = raw.annotator_id.unique()\n",
    "print(\"n_annotators:\", len(n_unique_annotators))\n",
    "print(\"max annotations by one person:\", raw.annotator_id.value_counts().max())\n",
    "print(\"min annotations by one person:\", raw.annotator_id.value_counts().min(),)\n",
    "print(\"mean annotations by one person:\", raw.annotator_id.value_counts().mean(),\"\\n\")\n",
    "\n",
    "print(\"n_unique images annotated:\", len(raw.c10_train_index.unique()))\n",
    "print(\"max annotations per image:\", raw.c10_train_index.value_counts().max())\n",
    "print(\"min annotations per image:\", raw.c10_train_index.value_counts().min())\n",
    "print(\"mean annotations per image:\", raw.c10_train_index.value_counts().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_annotators = []\n",
    "min_labels_per_class = 20\n",
    "for annotator in n_unique_annotators:\n",
    "    rows = raw.loc[raw.annotator_id == annotator]\n",
    "    annotations = rows.loc[:,['chosen_label', 'true_label']]\n",
    "\n",
    "    cond1 = annotations.true_label.unique().shape[0] == 10 # checks if labeled images from every class\n",
    "    cond2 = annotations.true_label.value_counts().min() >= min_labels_per_class # checks if least number of images annotated from each class\n",
    "\n",
    "    if (cond1 and cond2):\n",
    "        chosen_annotators.append(annotator)\n",
    "\n",
    "chosen_annotators = np.array(chosen_annotators)\n",
    "chosen_annotators.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 79\n",
      "Testing: 80\n"
     ]
    }
   ],
   "source": [
    "# splitting traing/testing\n",
    "np.random.seed(0)\n",
    "usersToNoiseMat = np.random.choice(chosen_annotators, size=int(np.floor(chosen_annotators.__len__()*0.5)), replace=False)\n",
    "usersToTest = list(set(chosen_annotators) - set(usersToNoiseMat))\n",
    "print(\"Training:\", usersToNoiseMat.__len__())\n",
    "print(\"Testing:\", usersToTest.__len__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (79, 10, 20) (79, 10, 20)\n",
      "Testing (80, 10, 20) (80, 10, 20)\n"
     ]
    }
   ],
   "source": [
    "def getUserLabels(userSet):\n",
    "    allUsers_chosen=[]\n",
    "    allUsers_gt=[]\n",
    "    for annotator in userSet:\n",
    "        rows = raw.loc[raw.annotator_id == annotator]\n",
    "        annotations = rows.loc[:,['c10_train_index', 'true_label', 'chosen_label']]\n",
    "\n",
    "        perUser_chosen = []\n",
    "        perUser_gt = []\n",
    "        for i in range(0,10):\n",
    "            # taking 'min_labels_per_class' instances as the no. of images from each class\n",
    "            perUser_chosen.append(random.sample(annotations.loc[annotations.true_label == i].chosen_label.tolist(), min_labels_per_class))\n",
    "            perUser_gt.append(np.repeat(i, min_labels_per_class).tolist())\n",
    "\n",
    "        allUsers_chosen.append(np.array(perUser_chosen))\n",
    "        allUsers_gt.append(np.array(perUser_gt))\n",
    "\n",
    "    allUsers_chosen = np.array(allUsers_chosen)\n",
    "    allUsers_gt = np.array(allUsers_gt)\n",
    "    return allUsers_chosen, allUsers_gt\n",
    "\n",
    "trainUsers_chosen, trainUsers_gt = getUserLabels(usersToNoiseMat)\n",
    "testUsers_chosen, testUsers_gt = getUserLabels(usersToTest)\n",
    "\n",
    "print(\"Training\", trainUsers_chosen.shape, trainUsers_gt.shape)\n",
    "print(\"Testing\", testUsers_chosen.shape, testUsers_gt.shape)\n",
    "\n",
    "# 3dims -> users, classes, labels for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [79]\n",
      "2 [34 45]\n",
      "3 [23 31 25]\n"
     ]
    }
   ],
   "source": [
    "# get annotator profiles based on labels provided by training users\n",
    "np.random.seed(0)\n",
    "user_cluster_relation = []\n",
    "for i in range(2,5):\n",
    "    fuzzy_kmeans = Fuzz.FuzzyKMeans(k=i, m=2)\n",
    "    fuzzy_kmeans.fit(trainUsers_chosen.reshape(-1, min_labels_per_class*10))\n",
    "    allocated_cluster = np.argmax(fuzzy_kmeans.fuzzy_labels_, axis=1)\n",
    "    user_cluster_relation.append(allocated_cluster)\n",
    "    \n",
    "    print(\"K={}, silhouette={}, user_distribution={}\".format(i, \n",
    "    silhouette_score(trainUsers_chosen.reshape(-1, min_labels_per_class*10), fuzzy_kmeans.labels_),\n",
    "    np.unique(allocated_cluster, return_counts=True)[1]\n",
    "    ))\n",
    "    \n",
    "user_cluster_relation = np.array(user_cluster_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting users belong to each cluster at each k\n",
    "k_to_cluster_to_users = []\n",
    "for j in range(0, user_cluster_relation.shape[0]):\n",
    "    k_to_cluster_to_users.append({i+1: (user_cluster_relation[j] == i).nonzero()[0] for i in np.unique(user_cluster_relation[j])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the best k from silhouette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{1: array([ 0,  1,  4,  5, 10, 14, 15, 16, 18, 19, 20, 21, 28, 29, 31, 32, 35,\n",
       "         37, 39, 40, 41, 43, 45, 48, 49, 51, 55, 56, 62, 65, 67, 69, 74, 76]),\n",
       "  2: array([ 2,  3,  6,  7,  8,  9, 11, 12, 13, 17, 22, 23, 24, 25, 26, 27, 30,\n",
       "         33, 34, 36, 38, 42, 44, 46, 47, 50, 52, 53, 54, 57, 58, 59, 60, 61,\n",
       "         63, 64, 66, 68, 70, 71, 72, 73, 75, 77, 78])}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_k = 2 # set the selected K from silhouette score\n",
    "k_to_cluster_to_users = [k_to_cluster_to_users[selected_k-2]]\n",
    "k_to_cluster_to_users # shows the users in the clusters of selected K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating augmented training and testing sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These sets are used to train and validate $m_\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting c10 test set labels\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "testset = torchvision.datasets.CIFAR10(root=\"../cifar10n_no_gt_modified/data/\", train=False, download=False, transform=transform)\n",
    "ori_test_labels = testset.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add noise to training sets and create some users for each cluster in each k\n",
    "np.random.seed(0)\n",
    "\n",
    "n_aug = 3 # can set the number of times to augment. 3 is the default used\n",
    "k_user_train = {}\n",
    "k_user_test = {}\n",
    "\n",
    "for k in range(0, k_to_cluster_to_users.__len__()):\n",
    "    noisy_users_train_in_k = []\n",
    "    noisy_users_test_in_k = []\n",
    "\n",
    "    # iterating clusters\n",
    "    for clus in k_to_cluster_to_users[k].keys():\n",
    "        chosen = np.array([trainUsers_chosen[u].reshape(-1,) for u in k_to_cluster_to_users[k][clus]]).flatten()\n",
    "        gt = np.array([trainUsers_gt[u].reshape(-1,) for u in k_to_cluster_to_users[k][clus]]).flatten()\n",
    "        \n",
    "        # augmenting\n",
    "        for i in range(0, n_aug):\n",
    "            noise_matrix = np.transpose(np.round(confusion_matrix(gt, chosen, normalize='true'), decimals=5))\n",
    "            noiseInjectedTrain = cleanlab.benchmarking.noise_generation.generate_noisy_labels(step2_labels, noise_matrix)\n",
    "            noiseInjectedTest = cleanlab.benchmarking.noise_generation.generate_noisy_labels(ori_test_labels, noise_matrix)\n",
    "\n",
    "            noisy_users_train_in_k.append(noiseInjectedTrain)\n",
    "            noisy_users_test_in_k.append(noiseInjectedTest)\n",
    "\n",
    "        # just checking the accuracy of each cluster\n",
    "        acc = classification_report(gt, chosen, output_dict=True)['accuracy']\n",
    "        print(\"cluster:\", clus, \"acc:\", acc)\n",
    "\n",
    "    noisy_users_train_in_k.append(step2_labels) # consensus labels are appended at the end to ease of access when training\n",
    "    k_user_train[selected_k] = np.array(noisy_users_train_in_k)\n",
    "    k_user_test[selected_k] = np.array(noisy_users_test_in_k)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*format of k_user_train*\n",
    "\n",
    "if selected_k is 2 and n_aug = 3, then k_user_train[2].shape would be (7, 50000).\n",
    "\n",
    "interpretation of 7:\n",
    "* 1,2,3 for augmentations of cluster 1 noise\n",
    "* 4,5,6 for augmentations of cluster 2 noise\n",
    "* 7 for consensus labels\n",
    "\n",
    "50000 comes from number of training samples in cifar 10\n",
    "\n",
    "*format of k_user_test*\n",
    "\n",
    "shape would be (6, 10000)\n",
    "6 - first 3 for cluster 1 and last 3 for cluster 2\n",
    "10000 is the number of test samples in cifar 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cifar10n_train_clustering_c10n.npy', 'wb') as f:\n",
    "    np.save(f, k_user_train)\n",
    "\n",
    "with open('cifar10n_test_clustering_c10n.npy', 'wb') as f:\n",
    "    np.save(f, k_user_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "noisy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
